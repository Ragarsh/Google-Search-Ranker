{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['travelers.com'], [13]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Please Note\n",
    "## Lines that need to be changed for a new ranking pull are indicated with an * \n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('/Applications/Data/anaconda/pkgs/requests-2.13.0-py27_0/lib/python2.7/site-packages')\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "Soup = BeautifulSoup\n",
    "from urlparse import urlparse\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import urllib2\n",
    "import time\n",
    "import collections\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from random import randint\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "#*\n",
    "competitors  = [ 'progressive.com', 'travelers.com', 'geico.com', 'libertymutual.com', 'allstate.com']\n",
    "keywords = ['car insurance', 'builders risk insurance', 'cyber insurance']\n",
    "car_insurance = [] \n",
    "builders_insurance = []\n",
    "cyber_insurance = []\n",
    "    \n",
    "\n",
    "#Scrape and pull search ranking for above keywords\n",
    "def google_rank_scraper(search):\n",
    "    url =[]\n",
    "    domain = []\n",
    "    rank = []\n",
    "    competitor = []\n",
    "    pages = ['0','10', '20','30','40']#,'50','60','70','80']\n",
    "    for i in pages:\n",
    "        address=\"https://www.google.com/search?q=%s&start=\" %(search)\n",
    "        address+=str(i)\n",
    "        #headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        r = requests.get(address)\n",
    "        resp = r.content\n",
    "        soup = BeautifulSoup(resp.decode('utf-8', 'ignore'))   \n",
    "        for x in soup.findAll('h3', attrs={'class':'r'}):\n",
    "            p = x.a['href'][7:]\n",
    "            a = p.rpartition('&sa')[0]\n",
    "            url.append(a)\n",
    "           \n",
    "    # Extract domain url's from website url's            \n",
    "    for i in range(0,len(url)):\n",
    "        string = str(url[i])\n",
    "        parsed_uri = urlparse(string)\n",
    "        domain_uri = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "        domain.append(domain_uri)\n",
    "\n",
    "\n",
    "    #find company url ranking in search results\n",
    "    for i in range(0,len(competitors)):\n",
    "        for j in range(0,len(domain)):\n",
    "            if competitors[i] in domain[j]:\n",
    "                rank.append(j)\n",
    "                competitor.append(competitors[i])\n",
    "    \n",
    "    if key == 0:\n",
    "        car_insurance.append([competitor,rank])  #*\n",
    "    elif key == 1:\n",
    "        builders_insurance.append([competitor,rank])  #*\n",
    "    elif key == 2:\n",
    "        cyber_insurance.append([competitor, rank])  #*\n",
    "            \n",
    "\n",
    "\n",
    "#Google Scraper ranking function implementation            \n",
    "key == 0\n",
    "for key in range(0,len(keywords)):\n",
    "    google_rank_scraper(keywords[key])\n",
    "                \n",
    "            \n",
    "#Output for domain's found            \n",
    "builders_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['travelers.com'], [2]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output for domain's found\n",
    "cyber_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['progressive.com',\n",
       "   'travelers.com',\n",
       "   'geico.com',\n",
       "   'libertymutual.com',\n",
       "   'allstate.com'],\n",
       "  [6, 27, 8, 1, 0]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output for domain's found\n",
    "car_insurance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
